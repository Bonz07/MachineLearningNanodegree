{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Capstone Project\n",
    "Andrew O'Gorman - August 05, 2018\n",
    "\n",
    "\n",
    "## I. Definition\n",
    "\n",
    "### Project Overview\n",
    "For my Capstone project I will be using a deep learning approach to attempt to solve the Humpback Whale Identification project on [Kaggle](https://www.kaggle.com/c/whale-categorization-playground). This is a similar image classification problem to the dog breed classification challenge in the Deep Learning section of the Machine Learning Nanodegree. I have chosen this domain as I care deeply about our oceans and maritime life. I have been fascinated by whales since visiting the [Natural History Museum](http://www.nhm.ac.uk/discover/news/2017/july/museum-unveils-hope-the-blue-whale-skeleton.html), London, as a child with my father and seeing the full skeleton of the blue whale. They are truly magnificent creatures; giants of the ocean and I feel passionately about helping organisations that support and monitor them. This project appeals to me as the work will help contribute to [Happy Whale's](https://happywhale.com/home) understanding of the movement of whales by using machine learning to dramatically increase the efficiency of this identification work. \n",
    "\n",
    "Whale tails (referred to as 'Flukes') are like a barcode or fingerprint, with enough information to identify an individual whale. [Traditionally](https://www.nationalgeographic.com/adventure/adventure-blog/2016/05/04/whos-that-whale-your-photo-could-help-i-d-a-humpback/), scientists and marine biologists have taken and amassed large numbers of photograpahs of whales and then had to manually attempt to match newly photographed whales with historic images. This process is time consuming and prone to a high degree of error, also there are challenges around getting the pictures due to the geographical spread of whales and the amount of time spent underwater. These are some of the reasons why this problem suits a machine learning approach.\n",
    "\n",
    "Previous work was done at the [University of Texas](https://link.springer.com/chapter/10.1007/3-540-45103-X_16) in 2003 to identify Humpback and Gray Whales using a patch-matching technique as a follow-up phase to WhaleNet once they specified the fluke type. More recently a team at the [University of Catalunya in Barcelona](https://arxiv.org/pdf/1604.05605.pdf) used convolutional neural networks to test the feasibility of using deep learning in whale recognition using the NOAA Fisheries dataset. Their paper outlines a successful approach to applying CNNs to identification of the heads of whales and so this seems like a good approach to build upon in this capstone project.\n",
    "\n",
    "I am keen to test my understanding of image recognition using Deep Learning as there are several additional projects I would like to conduct upon completion of my Nanodegree and so hope this Capstone Project will be the foundation of further work for me in this field.\n",
    "\n",
    "The dataset I will be using to train the model can be found [here](https://www.kaggle.com/c/whale-categorization-playground/download/train.zip) and the testing dataset [here](https://www.kaggle.com/c/whale-categorization-playground/download/test.zip).\n",
    "\n",
    "### Problem Statement\n",
    "The problem is to use the existing dataset of whale fluke images to build an understanding of each whale's unique characteristics of their tails. By using this understanding, we should then be able to take a new picture of a whale fluke and determine whether it matches a previously seen whale or whether it is in fact a new whale not previously seen in our dataset. \n",
    "\n",
    "This problem is an image recognition challenge given the unique features of a [whale's fluke](http://www.alaskahumpbacks.org/matching.html) as seen below:\n",
    "\n",
    "<img src=\"files/fluke.jpg\">\n",
    "\n",
    "This problem is a good one to solve as understanding and tracking whale populations across the globe will help in several fields including ocean conservation and global climate change. \n",
    "\n",
    "### Metrics\n",
    "The owners of the Kaggle competition hold a labelled list of the 15,611 testing images which result submissions are compared against. For each image in the test set I will predict up to 5 labels for the whale ID (e.g. **w_1287fbc**), where a whale is not predicted to be one of the existing whales in the training data they will be labelled as **new_whale**. The submissions file will contain a header and have the following format:\n",
    "\n",
    "    Image,Id\n",
    "    \n",
    "    00029b3a.jpg,new_whale w_1287fbc w_98baff9 w_7554f44 w_1eafe46\n",
    "    \n",
    "    0003c693.jpg,new_whale w_1287fbc w_98baff9 w_7554f44 w_1eafe46\n",
    "\n",
    "The submissions are evaluated according to the Mean Average Precision (MAP) as seen below:\n",
    "\n",
    "    MAP@5 = \\frac{1}{U} \\sum_{u=1}^{U}  \\sum_{k=1}^{min(n,5)} P(k)\n",
    "\n",
    "Where **U** is the number of images, **P(k)** is the precision at cut-off **k**, and **n** is the number predictions per image. Scores are between 0 and 1 with a score of 1 being a perfect match with no error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Analysis\n",
    "\n",
    "### Data Exploration\n",
    "The dataset I am using was provided by Happy Whale, a citizen science organisation helping to track individual whales throughout the world's oceans. The images were gathered from research institutions and public contributions. The images specifically targeted whale flukes with the aim of being used to help identify the migration patterns of whales over time so as a dataset is ideally suited to the proposed problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in the training data = 9850\n",
      "Total images in the test data =  15610\n",
      "Total unique whales in training data = 4251\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "training_df = pd.read_csv('../capstone/train.csv')\n",
    "number_whales = len(training_df['Id'].unique())\n",
    "\n",
    "print(\"Total images in the training data =\",len(os.listdir(\"../capstone/train\")) )\n",
    "print(\"Total images in the test data = \",len(os.listdir(\"../capstone/test\")))\n",
    "print(\"Total unique whales in training data =\",number_whales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Visualization\n",
    "The data consists of over 25,000 images of whale flukes, with 9850 labelled images in the training set and 15,610 images in the testing set. In total the dataset contains images for 4251 different whales if you include the category of new_whale. Each image varies in size (number of pixels), colour, quality (sharpness) and orientation as we can see below:\n",
    "\n",
    "| Colour landscape | Grayscale and blurry | Colour portrait |\n",
    "| - | - | - |\n",
    "|<img src=\"files/train/6c54a646.jpg\">|<img src=\"files/train/e976465c.jpg\">|<img src=\"files/train/ea5f45ca.jpg\">|\n",
    "\n",
    "I will first look to pre-process the data to standardise the size, colour and proportions of all the images. This will allow me to build, train and test a deep learning algorithm to help identify whales within the dataset. The data is already split into training and testing sets, however, I will look to further subdivide the training set as I build my model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAGDCAYAAACSmpzSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e200550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "buckets = Counter(training_df['Id'].value_counts().values)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(buckets)), list(buckets.values())[::-1])\n",
    "plt.xticks(range(len(buckets)), list(buckets.keys())[::-1])\n",
    "plt.title(\"Number of images per whale\")\n",
    "plt.xlabel('Number of images')\n",
    "plt.ylabel('Whales')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial analysis of the data reveals that of the 4251 whales in the dataset over 2000 of them have only one image, with around 4000 of the whales having less than 5 images to train on. I will therefore use Data Augmentation to help boost the number of training images for each whale which I will discuss below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of grey images: 48.93\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def is_grey_scale(img_path):\n",
    "    im = Image.open(img_path).convert('RGB')\n",
    "    w,h = im.size\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            r,g,b = im.getpixel((i,j))\n",
    "            if r != g != b: return False\n",
    "    return True\n",
    "\n",
    "greyscale = [is_grey_scale(f'../capstone/train/{i}') for i in training_df['Image'].sample(frac=0.1)]\n",
    "grey_percentage = round(sum([i for i in greyscale]) / len([i for i in greyscale]) * 100, 2)\n",
    "\n",
    "print(f\"Percentage of grey images: {grey_percentage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the above [code]((https://stackoverflow.com/questions/23660929/how-to-check-whether-a-jpeg-image-is-color-or-gray-scale-using-only-python-stdli) we can see that we have almost an equal split of grayscale and colour images in the training data set. I will therefore look to convert all images (both training and testing) to greyscale in my data pre-processing step.\n",
    "\n",
    "Given the three images above are all different sizes I can also explore how the size of the images varies across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAGmCAYAAADbMjjkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c2b43c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_sizes = Counter([Image.open(f'../capstone/train/{i}').size for i in training_df['Image']])\n",
    "\n",
    "size, freq = zip(*Counter({i: v for i, v in img_sizes.items() if v > 1}).most_common(20))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar(range(len(freq)), list(freq), align='center')\n",
    "plt.xticks(range(len(size)), list(size), rotation=90)\n",
    "plt.title(\"Image size counts\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can clearly see the image size varies significantly across the dataset. I will look to address this in the Data Preprocessing section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms and Techniques\n",
    "I will be using a Deep Learning approach for this image identification problem. Deep Learning makes use of neural networks which aim to mimic how the brain operates with neurons used to fire pieces of information through a network to produce an output. By using this approach and building complex neural networks, Deep Learning can be more effective at determining the important features in a given image than a human. \n",
    "\n",
    "Specifically, I intend to use Convolutional Neural Networks (CNNs) for this problem. I have chosen to use CNNs for several reasons:\n",
    "\n",
    "-  CNNs maintain spatial information by taking matrices as inputs when compared to traditional Multilayer Perceptrons. This allows us to use fewer weights as some parameters are shared, hence lowering the computational cost and training time.\n",
    "\n",
    "- CNNs work well across images where there are distortions due to lighting conditions, horizontal/vertical shifts, different poses etc.\n",
    "\n",
    "- They are very good at identifying patterns within images by using filters to find specific groups of pixel groupings that are important.\n",
    "\n",
    "### Benchmark\n",
    "The benchmark score I will be comparing against was achieved using a technique known as [Perceptual hashing](https://en.wikipedia.org/wiki/Perceptual_hashing) (pHash). The pHash algorithm produces a fingerprint for each image which are analogous if features in the images are similar. This technique has been used previously to identify cases of online copyright infringement and also in digital forensics work due to its ability to have a correlation between hashes so similar images can be identified. \n",
    "\n",
    "The pHash technique is able to identify which whale IDs the image is most similar to and then submit their 5 most likely matches for each image. This benchmark submission was then measured using the MAP formula below to get a Mean Average Position score of 0.36075."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Methodology\n",
    "_(approx. 3-5 pages)_\n",
    "\n",
    "### Data Preprocessing\n",
    "In this section, all of your preprocessing steps will need to be clearly documented, if any were necessary. From the previous section, any of the abnormalities or characteristics that you identified about the dataset will be addressed and corrected here. Questions to ask yourself when writing this section:\n",
    "- _If the algorithms chosen require preprocessing steps like feature selection or feature transformations, have they been properly documented?_\n",
    "- _Based on the **Data Exploration** section, if there were abnormalities or characteristics that needed to be addressed, have they been properly corrected?_\n",
    "- _If no preprocessing is needed, has it been made clear why?_\n",
    "\n",
    "To do:\n",
    "\n",
    "* write code for one image to test it, then connect to TensorFlow and run for all images and then save in augmented training folder.\n",
    "* convert to greyscale\n",
    "* convert all images to standard size\n",
    "* remove any text/background noise from image by focusing on flukes\n",
    "* ensure all images are rotated so fluke pointing upwards\n",
    "* augment images to include variation and boost numbers per image\n",
    "* check to make sure all above has worked\n",
    "* once happy with this I will need to run same preprocessing over testing data also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing images\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-1aa72f93b322>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepareImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9850\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-1aa72f93b322>\u001b[0m in \u001b[0;36mprepareImages\u001b[0;34m(data, m, dataset)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#load images into images of size 100x100x3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/whale-categorization-playground/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m#x = np.expand_dims(x, axis=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the data\n",
    "\n",
    "train_images = glob(\"../input/train/*jpg\")\n",
    "test_images = glob(\"../input/test/*jpg\")\n",
    "df = pd.read_csv(\"../input/train.csv\")\n",
    "\n",
    "df[\"Image\"] = df[\"Image\"].map( lambda x : \"../input/train/\"+x)\n",
    "ImageToLabelDict = dict( zip( df[\"Image\"], df[\"Id\"]))\n",
    "\n",
    "# resize and convert to black and white\n",
    "\n",
    "SIZE = 64\n",
    "#image are imported with a resizing and a black and white conversion\n",
    "def ImportImage( filename):\n",
    "    img = Image.open(filename).convert(\"LA\").resize( (SIZE,SIZE))\n",
    "    return np.array(img)[:,:,0]\n",
    "train_img = np.array([ImportImage( img) for img in train_images])\n",
    "x = train_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-29a1fadb6fbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgrey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgreyscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgreyscale_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../capstone/train/{i}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-29a1fadb6fbb>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgrey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgreyscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgreyscale_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../capstone/train/{i}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-29a1fadb6fbb>\u001b[0m in \u001b[0;36mgreyscale_convert\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# converts all images in training set to greyscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgreyscale_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mgrey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# one hot encoding of the images\n",
    "\n",
    "class LabelOneHotEncoder():\n",
    "    def __init__(self):\n",
    "        self.ohe = OneHotEncoder()\n",
    "        self.le = LabelEncoder()\n",
    "    def fit_transform(self, x):\n",
    "        features = self.le.fit_transform( x)\n",
    "        return self.ohe.fit_transform( features.reshape(-1,1))\n",
    "    def transform( self, x):\n",
    "        return self.ohe.transform( self.la.transform( x.reshape(-1,1)))\n",
    "    def inverse_tranform( self, x):\n",
    "        return self.le.inverse_transform( self.ohe.inverse_tranform( x))\n",
    "    def inverse_labels( self, x):\n",
    "        return self.le.inverse_transform( x)\n",
    "\n",
    "y = list(map(ImageToLabelDict.get, train_images))\n",
    "lohe = LabelOneHotEncoder()\n",
    "y_cat = lohe.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constructing class weights\n",
    "\n",
    "WeightFunction = lambda x : 1./x**0.75\n",
    "ClassLabel2Index = lambda x : lohe.le.inverse_tranform( [[x]])\n",
    "CountDict = dict( df[\"Id\"].value_counts())\n",
    "class_weight_dic = { lohe.le.transform( [image_name])[0] : WeightFunction(count) for image_name, count in CountDict.items()}\n",
    "del CountDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check to see if resizing and greyscale conversion have worked\n",
    "\n",
    "def plotImages( images_arr, n_images=4):\n",
    "    fig, axes = plt.subplots(n_images, n_images, figsize=(12,12))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        if img.ndim != 2:\n",
    "            img = img.reshape( (SIZE,SIZE))\n",
    "        ax.imshow( img, cmap=\"Greys_r\")\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plotImages( x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Image augmentation\n",
    "\n",
    "#use of an image generator for preprocessing and data augmentation\n",
    "x = x.reshape( (-1,SIZE,SIZE,1))\n",
    "input_shape = x[0].shape\n",
    "x_train = x.astype(\"float32\")\n",
    "y_train = y_cat\n",
    "\n",
    "image_gen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=.15,\n",
    "    height_shift_range=.15,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "#training the image preprocessing\n",
    "image_gen.fit(x_train, augment=True)\n",
    "\n",
    "#visualization of some images out of the preprocessing\n",
    "#augmented_images, _ = next( image_gen.flow( x_train, y_train.toarray(), batch_size=4*4))\n",
    "#plotImages( augmented_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build and train model\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = len(y_cat.toarray()[0])\n",
    "epochs = 9\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(48, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(48, (3, 3), activation='sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(48, (5, 5), activation='sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.33))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(36, activation='sigmoid'))\n",
    "model.add(Dropout(0.33))\n",
    "model.add(Dense(36, activation='sigmoid'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit_generator(image_gen.flow(x_train, y_train.toarray(), batch_size=batch_size),\n",
    "          steps_per_epoch=  x_train.shape[0]//batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          class_weight=class_weight_dic)\n",
    "\n",
    "#score = model.evaluate(x_train, y_train, verbose=0)\n",
    "#print('Training loss: {0:.4f}\\nTraining accuracy:  {1:.4f}'.format(*score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions for test samples and prediction export\n",
    "\n",
    "import warnings\n",
    "from os.path import split\n",
    "\n",
    "with open(\"sample_submission.csv\",\"w\") as f:\n",
    "    with warnings.catch_warnings():\n",
    "        f.write(\"Image,Id\\n\")\n",
    "        warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "        for image in test_images:\n",
    "            img = ImportImage( image)\n",
    "            x = img.astype( \"float32\")\n",
    "            #applying preprocessing to test images\n",
    "            x = image_gen.standardize( x.reshape(1,SIZE,SIZE))\n",
    "            \n",
    "            y = model.predict_proba(x.reshape(1,SIZE,SIZE,1))\n",
    "            predicted_args = np.argsort(y)[0][::-1][:5]\n",
    "            predicted_tags = lohe.inverse_labels( predicted_args)\n",
    "            image = split(image)[-1]\n",
    "            predicted_tags = \" \".join( predicted_tags)\n",
    "            f.write(\"%s,%s\\n\" %(image, predicted_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Methodology\n",
    "_(approx. 3-5 pages)_\n",
    "\n",
    "### Data Preprocessing\n",
    "In this section, all of your preprocessing steps will need to be clearly documented, if any were necessary. From the previous section, any of the abnormalities or characteristics that you identified about the dataset will be addressed and corrected here. Questions to ask yourself when writing this section:\n",
    "- _If the algorithms chosen require preprocessing steps like feature selection or feature transformations, have they been properly documented?_\n",
    "- _Based on the **Data Exploration** section, if there were abnormalities or characteristics that needed to be addressed, have they been properly corrected?_\n",
    "- _If no preprocessing is needed, has it been made clear why?_\n",
    "\n",
    "### Implementation\n",
    "In this section, the process for which metrics, algorithms, and techniques that you implemented for the given data will need to be clearly documented. It should be abundantly clear how the implementation was carried out, and discussion should be made regarding any complications that occurred during this process. Questions to ask yourself when writing this section:\n",
    "- _Is it made clear how the algorithms and techniques were implemented with the given datasets or input data?_\n",
    "- _Were there any complications with the original metrics or techniques that required changing prior to acquiring a solution?_\n",
    "- _Was there any part of the coding process (e.g., writing complicated functions) that should be documented?_\n",
    "\n",
    "### Refinement\n",
    "In this section, you will need to discuss the process of improvement you made upon the algorithms and techniques you used in your implementation. For example, adjusting parameters for certain models to acquire improved solutions would fall under the refinement category. Your initial and final solutions should be reported, as well as any significant intermediate results as necessary. Questions to ask yourself when writing this section:\n",
    "- _Has an initial solution been found and clearly reported?_\n",
    "- _Is the process of improvement clearly documented, such as what techniques were used?_\n",
    "- _Are intermediate and final solutions clearly reported as the process is improved?_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Results\n",
    "_(approx. 2-3 pages)_\n",
    "\n",
    "### Model Evaluation and Validation\n",
    "In this section, the final model and any supporting qualities should be evaluated in detail. It should be clear how the final model was derived and why this model was chosen. In addition, some type of analysis should be used to validate the robustness of this model and its solution, such as manipulating the input data or environment to see how the models solution is affected (this is called sensitivity analysis). Questions to ask yourself when writing this section:\n",
    "- _Is the final model reasonable and aligning with solution expectations? Are the final parameters of the model appropriate?_\n",
    "- _Has the final model been tested with various inputs to evaluate whether the model generalizes well to unseen data?_\n",
    "- _Is the model robust enough for the problem? Do small perturbations (changes) in training data or the input space greatly affect the results?_\n",
    "- _Can results found from the model be trusted?_\n",
    "\n",
    "### Justification\n",
    "In this section, your models final solution and its results should be compared to the benchmark you established earlier in the project using some type of statistical analysis. You should also justify whether these results and the solution are significant enough to have solved the problem posed in the project. Questions to ask yourself when writing this section:\n",
    "- _Are the final results found stronger than the benchmark result reported earlier?_\n",
    "- _Have you thoroughly analyzed and discussed the final solution?_\n",
    "- _Is the final solution significant enough to have solved the problem?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Conclusion\n",
    "_(approx. 1-2 pages)_\n",
    "\n",
    "### Free-Form Visualization\n",
    "In this section, you will need to provide some form of visualization that emphasizes an important quality about the project. It is much more free-form, but should reasonably support a significant result or characteristic about the problem that you want to discuss. Questions to ask yourself when writing this section:\n",
    "- _Have you visualized a relevant or important quality about the problem, dataset, input data, or results?_\n",
    "- _Is the visualization thoroughly analyzed and discussed?_\n",
    "- _If a plot is provided, are the axes, title, and datum clearly defined?_\n",
    "\n",
    "### Reflection\n",
    "In this section, you will summarize the entire end-to-end problem solution and discuss one or two particular aspects of the project you found interesting or difficult. You are expected to reflect on the project as a whole to show that you have a firm understanding of the entire process employed in your work. Questions to ask yourself when writing this section:\n",
    "- _Have you thoroughly summarized the entire process you used for this project?_\n",
    "- _Were there any interesting aspects of the project?_\n",
    "- _Were there any difficult aspects of the project?_\n",
    "- _Does the final model and solution fit your expectations for the problem, and should it be used in a general setting to solve these types of problems?_\n",
    "\n",
    "### Improvement\n",
    "In this section, you will need to provide discussion as to how one aspect of the implementation you designed could be improved. As an example, consider ways your implementation can be made more general, and what would need to be modified. You do not need to make this improvement, but the potential solutions resulting from these changes are considered and compared/contrasted to your current solution. Questions to ask yourself when writing this section:\n",
    "- _Are there further improvements that could be made on the algorithms or techniques you used in this project?_\n",
    "- _Were there algorithms or techniques you researched that you did not know how to implement, but would consider using if you knew how?_\n",
    "- _If you used your final solution as the new benchmark, do you think an even better solution exists?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before submitting, ask yourself. . .**\n",
    "\n",
    "- Does the project report youve written follow a well-organized structure similar to that of the project template?\n",
    "- Is each section (particularly **Analysis** and **Methodology**) written in a clear, concise and specific fashion? Are there any ambiguous terms or phrases that need clarification?\n",
    "- Would the intended audience of your project be able to understand your analysis, methods, and results?\n",
    "- Have you properly proof-read your project report to assure there are minimal grammatical and spelling mistakes?\n",
    "- Are all the resources used for this project correctly cited and referenced?\n",
    "- Is the code that implements your solution easily readable and properly commented?\n",
    "- Does the code execute without error and produce results similar to those reported?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Resources\n",
    "\n",
    "* https://www.kaggle.com/c/whale-categorization-playground\n",
    "* http://www.nhm.ac.uk/discover/news/2017/july/museum-unveils-hope-the-blue-whale-skeleton.html\n",
    "* https://happywhale.com/home\n",
    "* https://www.nationalgeographic.com/adventure/adventure-blog/2016/05/04/whos-that-whale-your-photo-could-help-i-d-a-humpback/\n",
    "* https://link.springer.com/chapter/10.1007/3-540-45103-X_16\n",
    "* https://arxiv.org/pdf/1604.05605.pdf\n",
    "* http://www.alaskahumpbacks.org/matching.html\n",
    "* https://en.wikipedia.org/wiki/Perceptual_hashing\n",
    "* https://stackoverflow.com/questions/23660929/how-to-check-whether-a-jpeg-image-is-color-or-gray-scale-using-only-python-stdli\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
